{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6456bf37-ded5-4b91-a326-5968e005f7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_703/3280826788.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bef0b48bcff46fcaf68001fb242b4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from pickle import dump, load\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "\n",
    "# small library for seeing the progress of loops.\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c993209-0130-4c02-b585-f5afaca1714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_RAW = \"../data/raw\"\n",
    "DATASET_INTERIM = \"../data/interim\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0cd40-d8d3-425a-b7ce-b262d3e5d1d3",
   "metadata": {},
   "source": [
    "## Load & clean captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de0e1c05-28b2-4565-a983-69e75841cc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of captions: \t8091\n",
      "Length of vocab: \t8763\n"
     ]
    }
   ],
   "source": [
    "def clean_caption(caption, table):\n",
    "    caption.replace(\"-\", \" \")    # Replace \"-\" with \" \"\n",
    "    words = caption.split()      # Split the words\n",
    "    \n",
    "    words = [word.lower() for word in words]    # Convert to lowercase\n",
    "    words = [word.translate(table) for word in words]  # Remove punctuations\n",
    "    words = [word for word in words if(len(word)>1)]   # Remove 's and a\n",
    "    words = [word for word in words if(word.isalpha())] # Remove tokens with numbers\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def load_captions(filename):\n",
    "    # Load the text file into memory\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    \n",
    "    img_captions = dict()\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    for line in lines[1:]:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        img, caption = line.split(',', 1)\n",
    "        # Clean the caption text\n",
    "        caption = clean_caption(caption, table)\n",
    "        if img in img_captions:\n",
    "            img_captions[img].append(caption)\n",
    "        else:\n",
    "            img_captions[img] = [caption]\n",
    "        \n",
    "    return img_captions\n",
    "\n",
    "\n",
    "def text_vocabulary(img_captions):\n",
    "    vocab = set()\n",
    "    for img in img_captions:\n",
    "        [vocab.update(d.split()) for d in img_captions[img]]\n",
    "\n",
    "    return vocab\n",
    "\n",
    "img_captions = load_captions(os.path.join(DATASET_RAW, 'captions.txt'))\n",
    "print(f\"Number of captions: \\t{len(img_captions)}\")\n",
    "\n",
    "vocabulary = text_vocabulary(img_captions)\n",
    "print(f\"Length of vocab: \\t{len(vocabulary)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc8236d0-8cf1-4f92-a45f-8027aaa8e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_captions(img_captions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in img_captions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + '\\t' + desc )\n",
    "    data = \"\\n\".join(lines)\n",
    "    file = open(filename,\"w\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "save_img_captions(img_captions, os.path.join(DATASET_INTERIM, 'captions.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e368b52-345a-493a-afad-5ed9561e7197",
   "metadata": {},
   "source": [
    "## Extracting the features from images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d071a6b-a405-4918-aeaa-51826ac89feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 20:07:09.421439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:09.475971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:09.477446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:09.479969: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-04 20:07:09.488934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:09.489908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:09.490752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:16.622065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:16.622889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:16.623583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-04 20:07:16.624082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9352 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:00:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n",
      "83697664/83683744 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_703/3649821741.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for img in tqdm(os.listdir(directory)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ddcc4b1a8b4215a9280bd7e882ee22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 20:07:18.987298: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-04 20:07:23.180721: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2023-11-04 20:07:27.142004: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "def extract_img_features(directory):\n",
    "    model = Xception(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "    for img in tqdm(os.listdir(directory)):\n",
    "        filename = directory + \"/\" + img\n",
    "        image = Image.open(filename)\n",
    "        image = image.resize((299,299))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image/127.5\n",
    "        image = image - 1.0\n",
    "\n",
    "        feature = model.predict(image)\n",
    "        features[img] = feature\n",
    "    return features\n",
    "\n",
    "#2048 feature vector\n",
    "img_features = extract_img_features(os.path.join(DATASET_RAW, 'Images'))\n",
    "dump(img_features, open(os.path.join(DATASET_INTERIM, 'img_features.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e771dc3c-dcb7-456d-a9fe-1cf70082a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images:\t8091\n",
      "(1, 2048)\n"
     ]
    }
   ],
   "source": [
    "img_features = load(open(os.path.join(DATASET_INTERIM, 'img_features.pkl'),\"rb\"))\n",
    "\n",
    "print(f\"# of images:\\t{len(img_features)}\")\n",
    "print(img_features['1000268201_693b08cb0e.jpg'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75014495-8c97-48eb-a2d4-225705f8b9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245092ca-3d43-45ed-84b3-ccf69b39b738",
   "metadata": {},
   "source": [
    "## Split the training/dev/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70d49120-5277-468b-81d5-3fd8f14d0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 6000 | dev: 1000 | test: 1091\n"
     ]
    }
   ],
   "source": [
    "img_files = list(img_captions.keys())\n",
    "\n",
    "assert len(img_files) > 7000, \"The list must have more than 7000 elements.\"\n",
    "\n",
    "# Shuffle the list in place\n",
    "random.shuffle(img_files)\n",
    "\n",
    "# Split into training, dev, and test datasets\n",
    "train_imgs = img_files[:6000]\n",
    "dev_imgs = img_files[6000:7000]\n",
    "test_imgs = img_files[7000:]  # The remaining part of the list\n",
    "\n",
    "print(f\"train: {len(train_imgs)} | dev: {len(dev_imgs)} | test: {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d722219-3aa9-4d50-aa3b-f90d106166eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
